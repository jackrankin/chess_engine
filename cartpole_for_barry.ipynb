{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPtx8xHZJ2iyjG8ZgwSQMG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jackrankin/chess_engine/blob/main/cartpole_for_barry.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0YHUJOesk2G"
      },
      "outputs": [],
      "source": [
        "!pip install gymnasium\n",
        "!pip install renderlab"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gymnasium as gym\n",
        "import renderlab as rl\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from copy import deepcopy"
      ],
      "metadata": {
        "id": "bG55wmzfsmMw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Particle:\n",
        "  def __init__(self, env, sweep_depth):\n",
        "    self.env = env\n",
        "    self.sweep_depth = sweep_depth\n",
        "\n",
        "  def render(self):\n",
        "    print(self.env.state)\n",
        "\n",
        "  def push_forward(self):\n",
        "    cost, action = self.sweep(0)\n",
        "    return action, cost, cost == float('inf')\n",
        "\n",
        "  def sweep(self, depth):\n",
        "    if depth == self.sweep_depth:\n",
        "      return abs(self.env.state[2]), 0\n",
        "\n",
        "    minimum_cost = float('inf')\n",
        "    best_action = 0\n",
        "    og_state = self.env.state[:]\n",
        "\n",
        "    for action in range(2):\n",
        "      observation, reward, terminated, truncated, info = self.env.step(action)\n",
        "\n",
        "      if terminated or truncated:\n",
        "        self.env.unwrapped.state = og_state\n",
        "        continue\n",
        "\n",
        "      future_cost, future_action = self.sweep(depth+1)\n",
        "      self.env.unwrapped.state = og_state[:]\n",
        "\n",
        "      if future_cost < minimum_cost:\n",
        "        minimum_cost = future_cost\n",
        "        best_action = action\n",
        "\n",
        "    return minimum_cost, best_action"
      ],
      "metadata": {
        "id": "Er-7xRfQsowJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent():\n",
        "  def __init__(self, env, sweep_depth, num_particles, bucket_precision):\n",
        "    self.env = env\n",
        "    self.sweep_depth = sweep_depth\n",
        "    self.buckets = {}\n",
        "    self.particles = []\n",
        "    self.num_particles = num_particles\n",
        "    self.bucket_precision = bucket_precision\n",
        "\n",
        "  def seed_particles(self, agent_state):\n",
        "    for i in range(self.num_particles):\n",
        "      tmp_env = gym.make(\"CartPole-v1\")\n",
        "      tmp_env.reset()\n",
        "\n",
        "      # seed particles close to the agent's state, varying slightly for future sweeps\n",
        "\n",
        "      \"\"\"\n",
        "        MESS WITH THE -.5 to 0.5 RANGE\n",
        "\n",
        "\n",
        "      \"\"\"\n",
        "      tmp_env.unwrapped.state = [i + np.random.uniform(-0.5,0.5) for i in agent_state]\n",
        "      self.particles.append(Particle(tmp_env, self.sweep_depth))\n",
        "\n",
        "  def sweep_particles(self):\n",
        "    for i in range(self.num_particles):\n",
        "\n",
        "      action, cost, done = self.particles[i].push_forward()\n",
        "\n",
        "      if done:\n",
        "        continue\n",
        "\n",
        "      bucket = []\n",
        "\n",
        "      # buckets created by rounding the actions to bucket_precision decimals\n",
        "      for j in range(4):\n",
        "        bucket.append(round(self.particles[i].env.state[j], self.bucket_precision))\n",
        "\n",
        "      bucket = tuple(bucket)\n",
        "\n",
        "      # we choose to cache the action with the optimal reward\n",
        "      if cost < self.buckets.get(bucket, (float('inf'), float('inf')))[1]:\n",
        "        self.buckets[bucket] = (action, cost)\n",
        "\n",
        "  def push_forward(self):\n",
        "    state = []\n",
        "\n",
        "    for i in range(4):\n",
        "      state.append(round(self.env.state[i], self.bucket_precision))\n",
        "\n",
        "    state = tuple(state)\n",
        "\n",
        "    # find the nearest neighbors in the cache to determine the optimal action\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "      MESS WITH THE 100 NEIGHBORS\n",
        "\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    neigh = KNeighborsClassifier(100)\n",
        "\n",
        "    X = np.array(list(self.buckets.keys()))\n",
        "    Y = np.array([i[0] for i in self.buckets.values()])\n",
        "\n",
        "    neigh.fit(X,Y)\n",
        "    action = neigh.predict(np.array([state]))[0]\n",
        "    observation, reward, terminated, truncated, info = self.env.step(action)\n",
        "\n",
        "    return action, reward, terminated or truncated"
      ],
      "metadata": {
        "id": "oMgO6OsYsqU8"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make(\"CartPole-v1\", render_mode = \"rgb_array\")\n",
        "\n",
        "env.reset()\n",
        "\n",
        "\"\"\"\n",
        "  MESS WITH THE AGENT CONSTRUCTOR (3 and 2000)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "a = Agent(env, 3, 2000, 1) # sweepdepth, number of particles, and bucket_precision\n",
        "\n",
        "i = 0\n",
        "\n",
        "while True:\n",
        "\n",
        "  i += 1\n",
        "  a.seed_particles(a.env.state)\n",
        "  a.sweep_particles()\n",
        "  t = a.push_forward()\n",
        "  print(i, a.env.state)\n",
        "\n",
        "  if t[2] or i == 200: break"
      ],
      "metadata": {
        "id": "si0F8AL3swH4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}